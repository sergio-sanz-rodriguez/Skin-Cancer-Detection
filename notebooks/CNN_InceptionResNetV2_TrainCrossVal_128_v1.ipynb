{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f52785-438b-40f7-9ac8-2fcd3df4a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "#from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "import tensorflow as tf\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "# From TensorFlow\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, RandomRotation\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, ResNet50V2, EfficientNetB0, EfficientNetB4, EfficientNetB7, DenseNet121, ResNet152V2, InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.models import load_model, Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import AUC, PrecisionAtRecall, SpecificityAtSensitivity, PrecisionAtRecall\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# From scikit-learn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "#set_global_policy('mixed_float16')\n",
    "set_global_policy('float32')\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61af96-0a18-4379-9110-55a6a8b6bcab",
   "metadata": {},
   "source": [
    "# GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ce28b6-e439-4fff-8170-0412590d970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check for available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detected: {gpus}\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f4fa7-f20e-490d-9079-e6019e10d242",
   "metadata": {},
   "source": [
    "# Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d5b76a-44a5-43e7-96cc-c117f523fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "IM_SIZE = 128\n",
    "EPOCHS = 60\n",
    "LEARN_RATE = 0.0001\n",
    "REG_RATE = 0.001\n",
    "NEURONS_1 = 1024\n",
    "NEURONS_2 = 1024\n",
    "NEURONS_3 = 256\n",
    "DROPOUT_RATE = 0.5\n",
    "ACTIVATION = 'relu'\n",
    "BACKBONE = 'InceptionResNetV2'\n",
    "SEED_BALANCED = 23\n",
    "\n",
    "# Read the dataset\n",
    "ROOT_DATASET_DIR = \"../\"\n",
    "DATASET = os.path.join(ROOT_DATASET_DIR,\"images\")\n",
    "\n",
    "# Read the dataset\n",
    "file_name = os.path.join(\".\",\"train-metadata-eda-fe-v3-kaggle.csv\")\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc3a45-2d86-43cf-a7f9-823ad7d9a98c",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3863a7-37f8-4e8d-a471-0a7060fa449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_auc_score(y_actual, y_scores, tpr_threshold=0.80):\n",
    "    max_fpr = 1 - tpr_threshold\n",
    "\n",
    "    # create numpy arrays\n",
    "    y_actual = np.asarray(y_actual)\n",
    "    y_scores = np.asarray(y_scores)\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_actual, y_scores)\n",
    "\n",
    "    # Find the index where fpr exceeds max_fpr\n",
    "    stop_index = np.searchsorted(fpr, max_fpr, side='right')\n",
    "\n",
    "    if stop_index < len(fpr):\n",
    "        # Interpolate to find the TPR at max_fpr\n",
    "        fpr_interp_points = [fpr[stop_index - 1], fpr[stop_index]]\n",
    "        tpr_interp_points = [tpr[stop_index - 1], tpr[stop_index]]\n",
    "        tpr = np.append(tpr[:stop_index], np.interp(max_fpr, fpr_interp_points, tpr_interp_points))\n",
    "        fpr = np.append(fpr[:stop_index], max_fpr)\n",
    "    else:\n",
    "        tpr = np.append(tpr, 1.0)\n",
    "        fpr = np.append(fpr, max_fpr)\n",
    "\n",
    "    # Calculate partial AUC\n",
    "    partial_auc_value = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc_value\n",
    "    \n",
    "# ploting model loss during training, created by Daniel: https://medium.com/geekculture/how-to-plot-model-loss-while-training-in-tensorflow-9fa1a1875a5\n",
    "class plot_learning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b40f8-9bfb-49ee-a261-4ff60f7d566a",
   "metadata": {},
   "source": [
    "# Image Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd8dff23-ed2f-4c6e-b88d-21529c3a9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for custom normalization\n",
    "def custom_normalization(image):\n",
    "    image = image / 255.0\n",
    "    mean = tf.constant(MEAN, dtype=image.dtype)\n",
    "    std = tf.constant(STD, dtype=image.dtype)\n",
    "    image = (image - mean) / std  # Normalize each channel\n",
    "    return image\n",
    "\n",
    "rotate_image = RandomRotation(factor=0.2)\n",
    "\n",
    "def random_zoom(image, min_val=0.8, max_val=1.2):\n",
    "    # Random zoom\n",
    "    zoom_scale = tf.random.uniform([], minval=min_val, maxval=max_val)\n",
    "    original_size = tf.shape(image)[0:2]\n",
    "    new_size = tf.cast(zoom_scale * tf.cast(original_size, tf.float32), tf.int32)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, new_size[0], new_size[1])\n",
    "    image = tf.image.resize(image, original_size)\n",
    "    return image\n",
    "    \n",
    "# Function to add Gaussian noise\n",
    "def gaussian_noise(image, mean=0.0, stddev=0.1):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "    image = tf.add(image, noise)\n",
    "    return image\n",
    "\n",
    "def gaussian_blur(image, kernel_size=5, sigma=1.0): \n",
    "    kernel = gaussian_kernel(kernel_size, 0.0, sigma)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.squeeze(image, axis=0)\n",
    "    \n",
    "# Image augmentation\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)  # Horizontal flip\n",
    "    image = tf.image.random_flip_up_down(image) # Vertical flip\n",
    "    #angle = tf.random.uniform([], minval=-20, maxval=20)\n",
    "    image = rotate_image(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)  # Random brightness\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)  # Random contrast\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)  # Random saturation\n",
    "    #image = random_zoom(image, min_val=0.8, max_val=1.2)\n",
    "    #image = tf.image.random_hue(image, max_delta=0.1)\n",
    "    #image = gaussian_noise(image, mean=0.0, stddev=0.1) \n",
    "    #image = gaussian_blur(image, kernel_size=5, sigma=1.0)\n",
    "    return image, label\n",
    "\n",
    "# Parse and process images\n",
    "def parse_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IM_SIZE, IM_SIZE]) #, method=tf.image.ResizeMethod.LANCZOS3)\n",
    "    image = custom_normalization(image)\n",
    "    return image, label\n",
    "\n",
    "# Generate dataset from file paths\n",
    "def generate_dataset(file_paths, labels, batch_size, is_training):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=1000)  # Use a reasonable buffer size\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# List image paths and labels\n",
    "def get_image_paths_and_labels(directory):\n",
    "    data_dir = Path(directory)    \n",
    "    all_image_paths = list(data_dir.glob('*/*.jpg'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]    \n",
    "    all_labels = [0 if '\\\\0' in str(path) else 1 for path in all_image_paths]\n",
    "    return all_image_paths, all_labels\n",
    "\n",
    "\n",
    "def match_image_paths(X_fold, all_image_paths, all_labels):\n",
    "    # Create a DataFrame for all image paths and labels\n",
    "    df_all_data = pd.DataFrame({'image_path': all_image_paths, 'label': all_labels})\n",
    "    df_all_data['isic_id'] = df_all_data['image_path'].str.extract(r'(ISIC_\\d+)')\n",
    "\n",
    "    # Merge on 'isic_id' with a left join\n",
    "    df_merged = pd.merge(X_fold, df_all_data, on='isic_id', how='left', sort=False).set_index(X_fold.index)\n",
    "\n",
    "    # Check for missing data in columns that should have been filled from all_data_df\n",
    "    missing_data = df_merged[df_merged['image_path'].isna() | df_merged['label'].isna()]\n",
    "\n",
    "    # Check missing data\n",
    "    assert missing_data.empty, \"Missing data found in the following rows:\"\n",
    "\n",
    "    # Ensure that all rows from X_fold have a corresponding entry\n",
    "    assert len(X_fold) == len(df_merged), \"Mismatch in row count after merge\"\n",
    "\n",
    "    assert df_merged.index.equals(X_fold.index), \"Index mismatch after merge\"\n",
    "    \n",
    "    # Return paths and labels\n",
    "    return df_merged['image_path'].tolist(), df_merged['label'].tolist(), df_merged.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341151d1-bfe5-4e84-8e64-6c0945bc0d04",
   "metadata": {},
   "source": [
    "# Class Balance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d11eee-bc1f-4ccb-bd0b-d41e5ef0b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to undersample the majority class and oversample the minority class\n",
    "def balance_classes(image_paths, labels, majority_size=None, minority_size=None, seed=SEED):\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = image_paths[labels == 0]\n",
    "    majority_labels = labels[labels == 0]\n",
    "    \n",
    "    minority_class = image_paths[labels == 1]\n",
    "    minority_labels = labels[labels == 1]\n",
    "    \n",
    "    # Undersample the majority class if majority_size is specified\n",
    "    if majority_size and (majority_size < len(majority_class)):\n",
    "        majority_class_downsampled, majority_labels_downsampled = resample(\n",
    "            majority_class,\n",
    "            majority_labels,\n",
    "            replace=False,  # Sample without replacement\n",
    "            n_samples=majority_size,  # Number of samples after undersampling\n",
    "            random_state=seed  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        majority_class_downsampled, majority_labels_downsampled = majority_class, majority_labels\n",
    "    \n",
    "    # Oversample the minority class if minority_size is specified\n",
    "    if minority_size and (minority_size > len(minority_class)):\n",
    "        minority_class_upsampled, minority_labels_upsampled = resample(\n",
    "            minority_class,\n",
    "            minority_labels,\n",
    "            replace=True,  # Sample with replacement\n",
    "            n_samples=minority_size,  # Number of samples after oversampling\n",
    "            random_state=seed  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        minority_class_upsampled, minority_labels_upsampled = minority_class, minority_labels\n",
    "    \n",
    "    # Combine the undersampled majority class and upsampled minority class\n",
    "    balanced_image_paths = np.concatenate([majority_class_downsampled, minority_class_upsampled])\n",
    "    balanced_labels = np.concatenate([majority_labels_downsampled, minority_labels_upsampled])\n",
    "    \n",
    "    return balanced_image_paths.tolist(), balanced_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3348a-f4ab-4a81-9e74-23e81fbcad9a",
   "metadata": {},
   "source": [
    "# Create the CNN\n",
    "\n",
    "**Note**: This section shows the algorithm used to generate cross-validated CNN predition vector. This structure will be created during a stratifed K-fold cross-validation process to find the best CNN parameters. Predictions will be made out-of-sample using unseen data: for each fold, a CNN model is trained using 4 folds and predictions are made on the remaining fold. This apprach follows the principles to ensure the integrity of the final model avoiding data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0c008b-62aa-4268-9914-d866b9898225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the convolutional neural network. Based on ResNet152V2, the whole backbone and hidden layer will be trainen to achieve more accurate predictions\n",
    "def create_cnn_model():\n",
    "    \n",
    "    # Use InceptionResNetV2 as a backbone\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "\n",
    "    # Enable backbone training\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Generate a neural network with one hidden layer of 64 neurons\n",
    "    x = GlobalAveragePooling2D()(base_model.output)    \n",
    "    x = Dense(NEURONS_1, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    x = Dense(NEURONS_2, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    x = Dense(NEURONS_3, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Define optimizer and evaluation metrics\n",
    "    optimizer = Adam(learning_rate=LEARN_RATE)\n",
    "    eval_metrics = [\"accuracy\", AUC(from_logits=False), SpecificityAtSensitivity(sensitivity=0.8)]\n",
    "\n",
    "    # And compile\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=eval_metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb47ed-99a0-415f-bfe3-8d62cfb8d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "TRAIN_TEST_SPLIT = 0.15\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "all_image_paths, all_labels = get_image_paths_and_labels(DATASET + '/crossval')\n",
    "\n",
    "# Frequencies of class 1 (malign)\n",
    "n_class_1 = all_labels.count(1)\n",
    "\n",
    "# Apply stratified K-fold\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "cancer_prob_list = []\n",
    "pauc_scores = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "\n",
    "    X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Match train and validation images\n",
    "    image_train_fold, label_train_fold, index_train_fold = match_image_paths(X_train_fold, all_image_paths, all_labels)\n",
    "    image_test_fold, label_test_fold, index_test_fold = match_image_paths(X_test_fold, all_image_paths, all_labels)\n",
    "    \n",
    "    assert (test_idx == index_test_fold).all(), \"indexes are not the same\"\n",
    "    assert (y_test_fold.tolist() == label_test_fold), \"y_tests are not the same\"\n",
    "    \n",
    "    # Balance the classes by undersampling and oversampling\n",
    "    image_train_fold_balanced, label_train_fold_balanced = balance_classes(        \n",
    "        image_train_fold, \n",
    "        label_train_fold, \n",
    "        majority_size=n_class_1 * 10,  # Set this to the desired number of majority samples\n",
    "        minority_size=n_class_1 * 10,   # Set this to the desired number of minority samples\n",
    "        seed=SEED_BALANCED\n",
    "    )\n",
    "\n",
    "    # Split the data into training and validation sets.\n",
    "    # The validation set will be use to control the training process\n",
    "    train_paths, validation_paths, train_labels, validation_labels = train_test_split(\n",
    "        image_train_fold_balanced,\n",
    "        label_train_fold_balanced, \n",
    "        test_size=TRAIN_TEST_SPLIT,\n",
    "        stratify=label_train_fold_balanced, \n",
    "        random_state=SEED)\n",
    "\n",
    "    # Train CNN on the training fold\n",
    "    train_dataset =      generate_dataset(train_paths, train_labels, BATCH_SIZE, is_training=True)\n",
    "    validation_dataset = generate_dataset(validation_paths, validation_labels, BATCH_SIZE, is_training=False)\n",
    "    test_dataset =       generate_dataset(image_test_fold, label_test_fold, BATCH_SIZE, is_training=False)\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "\n",
    "        # Create and compile the CNN model\n",
    "        cnn_model = create_cnn_model()\n",
    "\n",
    "        # Enable reducing learning rate on plateau\n",
    "        reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, min_lr=1e-7)\n",
    "\n",
    "        filepath=f\"tmp.keras\"\n",
    "        checkpoint_callback = ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "        # Train the model on the current fold\n",
    "        cnn_model.fit(\n",
    "            train_dataset,\n",
    "            batch_size=BATCH_SIZE,    \n",
    "            epochs=EPOCHS,\n",
    "            verbose=1,\n",
    "            validation_data=validation_dataset,    \n",
    "            callbacks=[plot_learning(), reduce_lr_callback, checkpoint_callback]\n",
    "        )\n",
    "\n",
    "    # Load best model\n",
    "    cnn_model = load_model(filepath)\n",
    "\n",
    "    # Predict on the remaining\n",
    "    cancer_prob = cnn_model.predict(test_dataset)\n",
    "\n",
    "    pauc = partial_auc_score(y_test_fold, cancer_prob)\n",
    "    pauc_scores.append(pauc)\n",
    "    print(f'pAUC: {pauc}', flush=True)\n",
    "\n",
    "    # Store the features along with the corresponding indices\n",
    "    cancer_prob_list.append((test_idx, cancer_prob, pauc))\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac2fa0-ad10-4af1-bf25-1ec00373883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cross-validated CNN feature vector.\n",
    "cancer_prob_all = np.zeros((len(X), cancer_prob_list[0][1].shape[1]))  # Initialize full feature matrix\n",
    "merged_list = []\n",
    "fold = 1\n",
    "\n",
    "# Loop over the cancer probability list\n",
    "for test_idx, cancer_prob, pauc in cancer_prob_list:\n",
    "    assert len(test_idx) == len(cancer_prob), \"error\"\n",
    "    cancer_prob_all[test_idx] = cancer_prob\n",
    "    print(f\"Partial AUC score for fold {fold}: {pauc}\")\n",
    "    fold += 1\n",
    "    \n",
    "df_cnn = pd.DataFrame({'crossval_cnn_preds': cancer_prob_all.flatten()})\n",
    "df_cnn = pd.concat([df[['isic_id']], df_cnn, df[['target']]], axis=1)\n",
    "df_cnn.to_csv(f\"train-cnn-crossval-preds-{BACKBONE}_{IM_SIZE}_seed{SEED_BALANCED}_C.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5081e56-867e-4c8c-94f4-bf9803ab95a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce335bae-0f5c-44f6-ba61-ebbc1be9fc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf_gpu (py310)",
   "language": "python",
   "name": ".venv_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
