{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89a1d53-4314-4f79-8852-f261480192ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import time\n",
    "import logging\n",
    "\n",
    "## Feature-scaling stack\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "## Dimesionality reduction\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "## Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "## Machine-learning stack\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier \n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "## Metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, roc_auc_score, auc, fbeta_score, f1_score\n",
    "\n",
    "## Model saving\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e885ba1-971f-46a4-84ce-7ed1df1d992b",
   "metadata": {},
   "source": [
    "# Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff174bee-4ed4-41d5-8f83-19a64a529a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE = {\n",
    "    'rf':     {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'xgb':    {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'lgb':    {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'cb':     {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'ada':    {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'svc':    {'cross-val':    0,\n",
    "               'compute-pauc': 0,\n",
    "               'final-train':  0,\n",
    "               'save-model':   0,\n",
    "              },\n",
    "    'soft-v': {'cross-val':    0,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'lr-v':   {'cross-val':    1,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9e7df-b69a-4a8f-ab7a-8ba123f13735",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d18c79-052b-4c86-a5b6-d4794914e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_auc_score(y_actual, y_scores, tpr_threshold=0.80):\n",
    "    max_fpr = 1 - tpr_threshold\n",
    "\n",
    "    # create numpy arrays\n",
    "    y_actual = np.asarray(y_actual)\n",
    "    y_scores = np.asarray(y_scores)\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_actual, y_scores)\n",
    "\n",
    "    # Find the index where fpr exceeds max_fpr\n",
    "    stop_index = np.searchsorted(fpr, max_fpr, side='right')\n",
    "\n",
    "    if stop_index < len(fpr):\n",
    "        # Interpolate to find the TPR at max_fpr\n",
    "        fpr_interp_points = [fpr[stop_index - 1], fpr[stop_index]]\n",
    "        tpr_interp_points = [tpr[stop_index - 1], tpr[stop_index]]\n",
    "        tpr = np.append(tpr[:stop_index], np.interp(max_fpr, fpr_interp_points, tpr_interp_points))\n",
    "        fpr = np.append(fpr[:stop_index], max_fpr)\n",
    "    else:\n",
    "        tpr = np.append(tpr, 1.0)\n",
    "        fpr = np.append(fpr, max_fpr)\n",
    "\n",
    "    # Calculate partial AUC\n",
    "    partial_auc_value = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc_value\n",
    "\n",
    "def cross_val_partial_auc_score(X, y, model, n_splits):\n",
    "\n",
    "     # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    pauc_scores = []\n",
    "    cont = 1\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "        print(f'Processing fold {cont} of {n_splits}... ', end='', flush=True)\n",
    "        \n",
    "        # Create the folds\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "        # Predict on the validation set\n",
    "        preds = model.predict_proba(X_val_fold)[:,1]\n",
    "   \n",
    "        # Calculate partical AUC and store it\n",
    "        pauc = partial_auc_score(y_val_fold, preds)\n",
    "        pauc_scores.append(pauc)\n",
    "\n",
    "        print(f'pAUC: {pauc}', flush=True)\n",
    "        \n",
    "        cont = cont + 1\n",
    "\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    # Return the average\n",
    "    return np.mean(pauc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70699db-dd46-4fac-8217-3066d142c8a7",
   "metadata": {},
   "source": [
    "# Model Loading and Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2668c8fe-ed34-4cfc-9047-d4e643d26038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata-based feature set\n",
    "ROOT_DATASET_DIR = \"./\"\n",
    "file_name_data = os.path.join(ROOT_DATASET_DIR,\"train-metadata-eda-fe.csv\")\n",
    "df_data = pd.read_csv(file_name_data)\n",
    "\n",
    "# Read the image (pixel)-based feature set\n",
    "file_name_img = os.path.join(ROOT_DATASET_DIR,\"train-cnn-features-rn152v2.csv\")\n",
    "df_img = pd.read_csv(file_name_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263e30ee-ae18-45c6-bbf1-914c3fbce971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.drop(columns=['isic_id'], inplace=True)\n",
    "df_data['anatom_site_general'] = pd.Categorical(df_data['anatom_site_general'])\n",
    "df_data['tbp_lv_location'] = pd.Categorical(df_data['tbp_lv_location'])\n",
    "df_data['tbp_lv_location_simple'] = pd.Categorical(df_data['tbp_lv_location_simple'])\n",
    "df_data['sex'] = pd.Categorical(df_data['sex'])\n",
    "df_img.drop(columns=['target'], inplace=True)\n",
    "df = pd.concat([df_data, df_img], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba01303-7b84-449e-8e40-8c367efa51cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>tbp_lv_B</th>\n",
       "      <th>tbp_lv_Bext</th>\n",
       "      <th>...</th>\n",
       "      <th>im_feature_54</th>\n",
       "      <th>im_feature_55</th>\n",
       "      <th>im_feature_56</th>\n",
       "      <th>im_feature_57</th>\n",
       "      <th>im_feature_58</th>\n",
       "      <th>im_feature_59</th>\n",
       "      <th>im_feature_60</th>\n",
       "      <th>im_feature_61</th>\n",
       "      <th>im_feature_62</th>\n",
       "      <th>im_feature_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>16.261975</td>\n",
       "      <td>26.922447</td>\n",
       "      <td>23.954773</td>\n",
       "      <td>...</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.363</td>\n",
       "      <td>6.310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>2.627</td>\n",
       "      <td>3.842</td>\n",
       "      <td>2.242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>25.364740</td>\n",
       "      <td>26.331000</td>\n",
       "      <td>24.549290</td>\n",
       "      <td>...</td>\n",
       "      <td>3.277</td>\n",
       "      <td>2.197</td>\n",
       "      <td>5.420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.885</td>\n",
       "      <td>1.667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>17.128170</td>\n",
       "      <td>37.970460</td>\n",
       "      <td>33.485410</td>\n",
       "      <td>...</td>\n",
       "      <td>3.844</td>\n",
       "      <td>2.775</td>\n",
       "      <td>6.720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.877</td>\n",
       "      <td>2.416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>12.164757</td>\n",
       "      <td>21.448144</td>\n",
       "      <td>21.121356</td>\n",
       "      <td>...</td>\n",
       "      <td>3.650</td>\n",
       "      <td>2.547</td>\n",
       "      <td>6.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.803</td>\n",
       "      <td>2.271</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>20.057470</td>\n",
       "      <td>26.464900</td>\n",
       "      <td>25.710460</td>\n",
       "      <td>...</td>\n",
       "      <td>3.328</td>\n",
       "      <td>2.330</td>\n",
       "      <td>5.574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>2.488</td>\n",
       "      <td>3.332</td>\n",
       "      <td>2.027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  age_approx sex anatom_site_general  clin_size_long_diam_mm   \n",
       "0       0        60.0   0     lower extremity                    3.04  \\\n",
       "1       0        60.0   0           head/neck                    1.10   \n",
       "2       0        60.0   0     posterior torso                    3.40   \n",
       "3       0        65.0   0      anterior torso                    3.22   \n",
       "4       0        55.0   0      anterior torso                    2.73   \n",
       "\n",
       "   tbp_tile_type   tbp_lv_A  tbp_lv_Aext   tbp_lv_B  tbp_lv_Bext  ...   \n",
       "0              0  20.244422    16.261975  26.922447    23.954773  ...  \\\n",
       "1              0  31.712570    25.364740  26.331000    24.549290  ...   \n",
       "2              1  22.575830    17.128170  37.970460    33.485410  ...   \n",
       "3              1  14.242329    12.164757  21.448144    21.121356  ...   \n",
       "4              0  24.725520    20.057470  26.464900    25.710460  ...   \n",
       "\n",
       "   im_feature_54  im_feature_55  im_feature_56  im_feature_57  im_feature_58   \n",
       "0          3.312          2.363          6.310            0.0            0.0  \\\n",
       "1          3.277          2.197          5.420            0.0            0.0   \n",
       "2          3.844          2.775          6.720            0.0            0.0   \n",
       "3          3.650          2.547          6.395            0.0            0.0   \n",
       "4          3.328          2.330          5.574            0.0            0.0   \n",
       "\n",
       "   im_feature_59  im_feature_60  im_feature_61  im_feature_62  im_feature_63  \n",
       "0         0.8320          2.627          3.842          2.242            0.0  \n",
       "1         0.6885          2.225          2.885          1.667            0.0  \n",
       "2         1.0700          2.955          3.877          2.416            0.0  \n",
       "3         0.9190          2.780          3.803          2.271            0.0  \n",
       "4         0.8813          2.488          3.332          2.027            0.0  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701db7bd-99b3-4fc8-8319-55e01d5f00bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_approx</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>57.946816</td>\n",
       "      <td>13.546105</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>85.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>1.741947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>28.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.710966</td>\n",
       "      <td>0.453314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>19.961896</td>\n",
       "      <td>3.993054</td>\n",
       "      <td>-2.487115</td>\n",
       "      <td>17.325051</td>\n",
       "      <td>19.79291</td>\n",
       "      <td>22.289341</td>\n",
       "      <td>48.18961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_59</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.257739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.893600</td>\n",
       "      <td>1.73500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_60</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>2.097273</td>\n",
       "      <td>0.760955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.753000</td>\n",
       "      <td>2.23400</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.73400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_61</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>2.809590</td>\n",
       "      <td>1.064116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>2.97500</td>\n",
       "      <td>3.518000</td>\n",
       "      <td>7.11300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_62</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>1.712804</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.83200</td>\n",
       "      <td>2.146000</td>\n",
       "      <td>3.98800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_63</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.054119</td>\n",
       "      <td>0.369634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.39000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean        std       min        25%   \n",
       "target                  395303.0   0.000994   0.031515  0.000000   0.000000  \\\n",
       "age_approx              395303.0  57.946816  13.546105  5.000000  50.000000   \n",
       "clin_size_long_diam_mm  395303.0   3.930147   1.741947  1.000000   2.840000   \n",
       "tbp_tile_type           395303.0   0.710966   0.453314  0.000000   0.000000   \n",
       "tbp_lv_A                395303.0  19.961896   3.993054 -2.487115  17.325051   \n",
       "...                          ...        ...        ...       ...        ...   \n",
       "im_feature_59           395303.0   0.719197   0.257739  0.000000   0.587000   \n",
       "im_feature_60           395303.0   2.097273   0.760955  0.000000   1.753000   \n",
       "im_feature_61           395303.0   2.809590   1.064116  0.000000   2.287000   \n",
       "im_feature_62           395303.0   1.712804   0.642774  0.000000   1.404000   \n",
       "im_feature_63           395303.0   0.054119   0.369634  0.000000   0.000000   \n",
       "\n",
       "                             50%        75%       max  \n",
       "target                   0.00000   0.000000   1.00000  \n",
       "age_approx              60.00000  70.000000  85.00000  \n",
       "clin_size_long_diam_mm   3.37000   4.380000  28.40000  \n",
       "tbp_tile_type            1.00000   1.000000   1.00000  \n",
       "tbp_lv_A                19.79291  22.289341  48.18961  \n",
       "...                          ...        ...       ...  \n",
       "im_feature_59            0.76000   0.893600   1.73500  \n",
       "im_feature_60            2.23400   2.600000   4.73400  \n",
       "im_feature_61            2.97500   3.518000   7.11300  \n",
       "im_feature_62            1.83200   2.146000   3.98800  \n",
       "im_feature_63            0.00000   0.000000  12.39000  \n",
       "\n",
       "[188 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f0367-8caa-4ff7-aa2e-d7e4789ccecf",
   "metadata": {},
   "source": [
    "# Feature Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139c46c-3af3-4c68-b648-5a793b42b5ea",
   "metadata": {},
   "source": [
    "Some new features are from other notebooks at: https://www.kaggle.com/competitions/isic-2024-challenge/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e08914-1538-4ad4-be51-15b5ede13b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original feature names\n",
    "features_to_be_logtr = ['clin_size_long_diam_mm',\n",
    "                        'tbp_lv_areaMM2',\n",
    "                        'tbp_lv_area_perim_ratio',\n",
    "                        'tbp_lv_color_std_mean',\n",
    "                        'tbp_lv_deltaLB',\n",
    "                        'tbp_lv_deltaLBnorm',\n",
    "                        'tbp_lv_minorAxisMM',\n",
    "                        'tbp_lv_norm_border',\n",
    "                        'tbp_lv_norm_color',\n",
    "                        'tbp_lv_perimeterMM',\n",
    "                        'tbp_lv_radial_color_std_max',\n",
    "                        'tbp_lv_stdL',\n",
    "                        'tbp_lv_stdLExt',\n",
    "                        'tbp_lv_symm_2axis']\n",
    "features_to_be_sqrtr = ['tbp_lv_eccentricity']\n",
    "\n",
    "# Modified original feature names\n",
    "log_features = ['log_' + col for col in features_to_be_logtr]\n",
    "sqr_features = ['sqr_' + col for col in features_to_be_sqrtr]\n",
    "\n",
    "# New feature names\n",
    "new_features_to_be_logtr = ['hue_contrast',\n",
    "                            'luminance_contrast',\n",
    "                            'lesion_color_difference',\n",
    "                            'border_complexity',\n",
    "                            'perimeter_to_area_ratio',\n",
    "                            'area_to_perimeter_ratio',\n",
    "                            'lesion_visibility_score',\n",
    "                            'symmetry_border_consistency',\n",
    "                            'consistency_symmetry_border',\n",
    "                            'consistency_color',\n",
    "                            'size_age_interaction',\n",
    "                            'lesion_severity_index',\n",
    "                            'shape_complexity_index',\n",
    "                            'std_dev_contrast',\n",
    "                            'color_shape_composite_index',\n",
    "                            'symmetry_perimeter_interaction',\n",
    "                            'comprehensive_lesion_index',\n",
    "                            'border_color_interaction',\n",
    "                            'size_color_contrast_ratio',\n",
    "                            'age_normalized_nevi_confidence',\n",
    "                            'volume_approximation_3d',\n",
    "                            'color_range',\n",
    "                            'age_size_symmetry_index',\n",
    "                            'index_age_size_symmetry']\n",
    "new_features_to_be_sqrtr = ['lesion_shape_index',\n",
    "                            'position_distance_3d']\n",
    "new_features_to_be_sqrttr = ['color_consistency',\n",
    "                             'hue_color_std_interaction',\n",
    "                             'normalized_lesion_size',                            \n",
    "                             'color_variance_ratio',\n",
    "                             'color_asymmetry_index',\n",
    "                             'shape_color_consistency']\n",
    "\n",
    "# Modify the column names\n",
    "log_new_features = ['log_' + col for col in new_features_to_be_logtr]\n",
    "sqr_new_features = ['sqr_' + col for col in new_features_to_be_sqrtr]\n",
    "sqrt_new_features = ['sqrt_' + col for col in new_features_to_be_sqrttr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadd9db-35e8-4200-b759-22249bb1ed72",
   "metadata": {},
   "source": [
    "# Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "338967ee-6d89-4b7d-a463-11714c73d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "# Drop non-used features for the baseline + target\n",
    "X = df.drop(['target']\n",
    "             + features_to_be_logtr + features_to_be_sqrtr                                         # drop original features with skeweness (no transformation)                          \n",
    "             + new_features_to_be_logtr + new_features_to_be_sqrtr + new_features_to_be_sqrttr,    # drop new features with skeweness (no transformation)             \n",
    "             axis=1)\n",
    "y = df['target']\n",
    "#X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=TRAIN_TEST_SPLIT, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20253c01-6731-4329-aeba-4fb48c3dc7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['age_approx', 'tbp_tile_type', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_nevi_confidence', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'log_clin_size_long_diam_mm', 'log_tbp_lv_areaMM2', 'log_tbp_lv_area_perim_ratio', 'log_tbp_lv_color_std_mean', 'log_tbp_lv_deltaLB', 'log_tbp_lv_deltaLBnorm', 'log_tbp_lv_minorAxisMM', 'log_tbp_lv_norm_border', 'log_tbp_lv_norm_color', 'log_tbp_lv_perimeterMM', 'log_tbp_lv_radial_color_std_max', 'log_tbp_lv_stdL', 'log_tbp_lv_stdLExt', 'log_tbp_lv_symm_2axis', 'sqr_tbp_lv_eccentricity', 'lesion_size_ratio', 'color_contrast_index', 'log_lesion_area', 'mean_hue_difference', 'lesion_orientation_3d', 'overall_color_difference', 'border_color_interaction_2', 'age_normalized_nevi_confidence_2', 'border_length_ratio', 'log_hue_contrast', 'log_luminance_contrast', 'log_lesion_color_difference', 'log_border_complexity', 'log_perimeter_to_area_ratio', 'log_area_to_perimeter_ratio', 'log_lesion_visibility_score', 'log_symmetry_border_consistency', 'log_consistency_symmetry_border', 'log_consistency_color', 'log_size_age_interaction', 'log_lesion_severity_index', 'log_shape_complexity_index', 'log_std_dev_contrast', 'log_color_shape_composite_index', 'log_symmetry_perimeter_interaction', 'log_comprehensive_lesion_index', 'log_border_color_interaction', 'log_size_color_contrast_ratio', 'log_age_normalized_nevi_confidence', 'log_volume_approximation_3d', 'log_color_range', 'log_age_size_symmetry_index', 'log_index_age_size_symmetry', 'sqr_lesion_shape_index', 'sqr_position_distance_3d', 'sqrt_color_consistency', 'sqrt_hue_color_std_interaction', 'sqrt_normalized_lesion_size', 'sqrt_color_variance_ratio', 'sqrt_color_asymmetry_index', 'sqrt_shape_color_consistency', 'im_feature_0', 'im_feature_1', 'im_feature_2', 'im_feature_3', 'im_feature_4', 'im_feature_5', 'im_feature_6', 'im_feature_7', 'im_feature_8', 'im_feature_9', 'im_feature_10', 'im_feature_11', 'im_feature_12', 'im_feature_13', 'im_feature_14', 'im_feature_15', 'im_feature_16', 'im_feature_17', 'im_feature_18', 'im_feature_19', 'im_feature_20', 'im_feature_21', 'im_feature_22', 'im_feature_23', 'im_feature_24', 'im_feature_25', 'im_feature_26', 'im_feature_27', 'im_feature_28', 'im_feature_29', 'im_feature_30', 'im_feature_31', 'im_feature_32', 'im_feature_33', 'im_feature_34', 'im_feature_35', 'im_feature_36', 'im_feature_37', 'im_feature_38', 'im_feature_39', 'im_feature_40', 'im_feature_41', 'im_feature_42', 'im_feature_43', 'im_feature_44', 'im_feature_45', 'im_feature_46', 'im_feature_47', 'im_feature_48', 'im_feature_49', 'im_feature_50', 'im_feature_51', 'im_feature_52', 'im_feature_53', 'im_feature_54', 'im_feature_55', 'im_feature_56', 'im_feature_57', 'im_feature_58', 'im_feature_59', 'im_feature_60', 'im_feature_61', 'im_feature_62', 'im_feature_63'] - Length: 140\n",
      "Categorical features: ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple'] - Length: 4\n"
     ]
    }
   ],
   "source": [
    "numerical_features = X.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "print(f\"Numerical features: {numerical_features} - Length: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {categorical_features} - Length: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efbb88-9160-4eb4-947a-92fe29f5a4ff",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f1bbbf-0333-4536-a7ea-ef055103995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant numerical features: 131\n",
      "\n",
      "                                        Score   P-Value\n",
      "Feature                                                \n",
      "im_feature_28                    38498.512139  0.000000\n",
      "im_feature_17                    37569.437479  0.000000\n",
      "im_feature_10                    37105.093383  0.000000\n",
      "im_feature_29                    37097.916715  0.000000\n",
      "im_feature_19                    36514.406202  0.000000\n",
      "...                                       ...       ...\n",
      "lesion_size_ratio                   10.627077  0.001115\n",
      "log_symmetry_border_consistency      8.738379  0.003116\n",
      "tbp_lv_L                             6.699025  0.009647\n",
      "sqrt_hue_color_std_interaction       6.449304  0.011100\n",
      "sqrt_color_variance_ratio            3.877523  0.048937\n",
      "\n",
      "[131 rows x 2 columns]\n",
      "Number of relevant categorical features: 8\n",
      "\n",
      "                                              Score       P-Value\n",
      "Feature                                                          \n",
      "anatom_site_general_head/neck            364.361682  3.161229e-81\n",
      "tbp_lv_location_Right Leg - Upper         15.614025  7.767632e-05\n",
      "tbp_lv_location_simple_Right Leg           8.605018  3.352381e-03\n",
      "anatom_site_general_lower extremity        8.463089  3.624258e-03\n",
      "tbp_lv_location_Left Leg                   8.314718  3.932510e-03\n",
      "tbp_lv_location_Torso Front Bottom Half    5.201509  2.256728e-02\n",
      "tbp_lv_location_Torso Back Middle Third    4.221756  3.990885e-02\n",
      "tbp_lv_location_Left Leg - Upper           3.866920  4.924681e-02\n"
     ]
    }
   ],
   "source": [
    "# Use SelectKBest (f_classif) for numerical features\n",
    "Kbest_numerical = SelectKBest(score_func=f_classif, k='all')\n",
    "Kbest_numerical.fit(X[numerical_features], y)\n",
    "\n",
    "# Extract feature scores and p-values\n",
    "scores = Kbest_numerical.scores_\n",
    "pvalues = Kbest_numerical.pvalues_\n",
    "\n",
    "# Create a DataFrame to save feature names, scores, and p-values\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Score': scores,\n",
    "    'P-Value': pvalues\n",
    "})\n",
    "\n",
    "# Sort features by 'Score'\n",
    "best_feature_scores = feature_scores[feature_scores['P-Value'] < 0.05]\n",
    "sorted_features = best_feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Display the sorted features\n",
    "KBEST_NUM = sorted_features.shape[0]\n",
    "print(f\"Number of relevant numerical features: {KBEST_NUM}\\n\")\n",
    "print(sorted_features.set_index('Feature'))\n",
    "\n",
    "# Use SelectKBest (chi2) for categorical features\n",
    "\n",
    "# Build a pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('onehot', preprocessor),\n",
    "    ('kbest', SelectKBest(score_func=chi2, k='all'))\n",
    "])\n",
    "\n",
    "cat_transformed = pipeline.fit_transform(X, y)\n",
    "Kbest_categorical = pipeline.named_steps['kbest']\n",
    "\n",
    "# Extract feature scores and p-values\n",
    "scores = Kbest_categorical.scores_\n",
    "pvalues = Kbest_categorical.pvalues_\n",
    "\n",
    "# Extract feature names after one-hot encoding\n",
    "one_hot_feature_names = pipeline.named_steps['onehot'].transformers_[0][1].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Create a DataFrame to hold feature names, scores, and p-values\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': one_hot_feature_names,\n",
    "    'Score': scores,\n",
    "    'P-Value': pvalues\n",
    "})\n",
    "\n",
    "# Sort features by their scores\n",
    "best_feature_scores = feature_scores[feature_scores['P-Value'] < 0.05]\n",
    "sorted_features = best_feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Display the sorted features\n",
    "KBEST_CAT = sorted_features.shape[0]\n",
    "print(f\"Number of relevant categorical features: {KBEST_CAT}\\n\")\n",
    "print(sorted_features.set_index('Feature'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d1e34-3ff4-4b41-a175-dd575cbdf9e3",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ea1aeb-c796-42c2-a8e0-407d2110162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "   \n",
    "pipe_num = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('kbest', SelectKBest(score_func=f_classif, k=KBEST_NUM)),   \n",
    "])\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)),\n",
    "    ('kbest', SelectKBest(score_func=chi2, k=KBEST_CAT)),    \n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[\n",
    "    ('numerical', pipe_num, numerical_features),\n",
    "    ('categorical',pipe_cat, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369183e0-1e6b-4909-81ff-e11389f7d710",
   "metadata": {},
   "source": [
    "# Balanced Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd36609-43cf-4470-885b-55f387672192",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92a5549-b2f0-4b33-9264-3805fb66fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 400)\n",
    "        max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10) #7)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10) #5)   \n",
    "        bootstrap=True\n",
    "        class_weight='balanced_subsample'\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                        \n",
    "            # Pipeline                           \n",
    "            pipe_rf = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('RF', BalancedRandomForestClassifier(random_state=42,\n",
    "                                                      n_estimators=n_estimators,\n",
    "                                                      max_depth=max_depth,\n",
    "                                                      min_samples_split=min_samples_split,\n",
    "                                                      min_samples_leaf=min_samples_leaf,\n",
    "                                                      bootstrap=bootstrap,\n",
    "                                                      class_weight=class_weight\n",
    "                                                     )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_rf.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_rf.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "#Best trial number: 18\n",
    "#Best value (partial auc - 0.8): 0.19099394435542486\n",
    "#Best hyperparameters: {'n_estimators': 138, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb8084-17ee-40c4-b354-6ce04033fafa",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0ac8a7-be36-4596-b3dd-782059669ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 138,\n",
    "        'max_depth': 12,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 8,\n",
    "        'bootstrap': True,\n",
    "        'class_weight': 'balanced_subsample',\n",
    "        'n_jobs': -1\n",
    "}\n",
    "\n",
    "model_rf_cv = ImbPipeline([    \n",
    "    ('preprocessing', preprocessing),\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "    ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "    ('RF',  BalancedRandomForestClassifier(**param_rf))\n",
    "])\n",
    "\n",
    "if ENABLE['rf']['compute-pauc'] == 1:\n",
    "    pauc_rf_cv = cross_val_partial_auc_score(X, y, model_rf_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_rf_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46150e09-685c-4105-9b33-05db0bf36755",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae79e0c8-b308-4ce2-ba32-05986a0decdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['final-train'] == 1:\n",
    "    \n",
    "    model_rf_fe139_rsmpl = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('RF',  BalancedRandomForestClassifier(**param_rf))\n",
    "    ])\n",
    "    \n",
    "    model_rf_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421dda50-dac8-4330-b5a2-308d6fd0be24",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20321e83-57b0-4d33-be7a-f28f0ad7c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['save-model'] == 1:\n",
    "    dump(model_rf_fe139_rsmpl, 'model_rf_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6501f-5cdb-48da-9892-987af7a88f6d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aed3d-aefa-41ee-82fd-603a27dedee3",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1202ac58-2815-4634-b924-838c0495159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['cross-val'] == 1:\n",
    "\n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 400)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.080, 0.090)\n",
    "        reg_lambda = trial.suggest_float('reg_lambda', 5.0, 10.0)\n",
    "        alpha = trial.suggest_float('alpha', 0.5, 0.8)\n",
    "        max_depth = trial.suggest_int('max_depth', 10, 31)\n",
    "        subsample = trial.suggest_float('subsample', 0.45, 0.70)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.80, 1.0)\n",
    "        colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.4, 0.7)\n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1, 10)\n",
    "        eval_metric = 'logloss'\n",
    "        enable_categorical = True\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline                           \n",
    "            pipe_xgb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('XGB', XGBClassifier(random_state=42,\n",
    "                                      enable_categorical=enable_categorical,\n",
    "                                      eval_metric=eval_metric,\n",
    "                                      n_estimators=n_estimators,\n",
    "                                      learning_rate=learning_rate,\n",
    "                                      reg_lambda=reg_lambda,\n",
    "                                      alpha=alpha,\n",
    "                                      max_depth=max_depth,\n",
    "                                      subsample=subsample,\n",
    "                                      colsample_bytree=colsample_bytree,\n",
    "                                      colsample_bylevel=colsample_bylevel,                             \n",
    "                                      scale_pos_weight=scale_pos_weight,\n",
    "                                    )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_xgb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_xgb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "#Best trial number: 80\n",
    "#Best value (partial auc - 0.8): 0.1917259326323112\n",
    "#Best hyperparameters: {'n_estimators': 208, 'learning_rate': 0.08256404336718554, 'reg_lambda': 6.1374965163887305, 'alpha': 0.6026870768041418, 'max_depth': 21, 'subsample': 0.47434308951793386, 'colsample_bytree': 0.9081510010036246, 'colsample_bylevel': 0.5171030271682259, 'scale_pos_weight': 9.454864886835315}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebc687-989a-47e9-b524-9dbcc6b7e7b1",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ed626e-6394-44ef-b5f3-2c15f2ec3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {\n",
    "        'random_state':      42,\n",
    "        'n_estimators':      208,\n",
    "        'learning_rate':     0.08256404336718554,\n",
    "        'reg_lambda':        6.1374965163887305,\n",
    "        'alpha':             0.6026870768041418,\n",
    "        'max_depth':         21,\n",
    "        'subsample':         0.47434308951793386,\n",
    "        'colsample_bytree':  0.9081510010036246,\n",
    "        'colsample_bylevel': 0.5171030271682259,\n",
    "        'scale_pos_weight':  9.454864886835315\n",
    "    }\n",
    "\n",
    "model_xgb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('RF',  XGBClassifier(**param_xgb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['xgb']['compute-pauc'] == 1:\n",
    "    pauc_xgb_cv = cross_val_partial_auc_score(X, y, model_xgb_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_xgb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f9aef-c4db-40c9-a86e-4a7d06942446",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36531ee-1dc3-45e0-9a33-6b90c2bc07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['final-train'] == 1:\n",
    "                           \n",
    "    model_xgb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('XGB', XGBClassifier(**param_xgb))\n",
    "    ])\n",
    "    \n",
    "    model_xgb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308ee8b-6035-4afc-86b0-ec6016516876",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e6fa867-1b9a-4f68-8944-b7d7cd5a499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['save-model'] == 1:\n",
    "    dump(model_xgb_fe139_rsmpl, 'model_xgb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7e44e-7a7c-49b0-85a2-016f63d7b1c9",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9abab-1503-49d3-9584-dc4ef04d138b",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ceeb482-0711-4561-baf7-e0a91be4beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "        \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        objective = 'binary'\n",
    "        boosting_type = 'gbdt'\n",
    "        verbosity = -1\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 500)    \n",
    "        lambda_l1 = trial.suggest_float('lambda_l1', 0.05, 0.10)\n",
    "        lambda_l2 = trial.suggest_float('lambda_l2', 0.001, 0.010)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0)\n",
    "        max_depth = trial.suggest_int('max_depth', 20, 50)    \n",
    "        num_leaves = trial.suggest_int('num_leaves', 20, 20)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "        colsample_bynode = trial.suggest_float('colsample_bynode', 0.1, 1.0)\n",
    "        bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0) \n",
    "        bagging_freq = trial.suggest_int('bagging_freq', 0, 15)\n",
    "        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 10)\n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1.0, 10.0)\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                        \n",
    "            # Pipeline\n",
    "            pipe_lgb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('LGB', LGBMClassifier(random_state=random_state,\n",
    "                                       verbosity=verbosity,\n",
    "                                       objective=objective,\n",
    "                                       boosting_type=boosting_type,                                   \n",
    "                                       n_estimators=n_estimators,\n",
    "                                       lambda_l1=lambda_l1,\n",
    "                                       lambda_l2=lambda_l2,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       max_depth=max_depth,\n",
    "                                       num_leaves=num_leaves,\n",
    "                                       colsample_bytree=colsample_bytree,\n",
    "                                       colsample_bynode=colsample_bynode,\n",
    "                                       bagging_fraction=bagging_fraction,\n",
    "                                       bagging_freq=bagging_freq,\n",
    "                                       min_data_in_leaf=min_data_in_leaf,\n",
    "                                       scale_pos_weight=scale_pos_weight\n",
    "                                      )         \n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_lgb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_lgb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "        \n",
    "#Best value (partial auc - 0.8): 0.19165167013143908\n",
    "#Best hyperparameters: {'n_estimators': 390, 'lambda_l1': 0.05127158993500609, 'lambda_l2': 0.002856268451232568, 'learning_rate': 0.016316428473444125, 'max_depth': 32, 'num_leaves': 20, 'colsample_bytree': 0.501841654985379, 'colsample_bynode': 0.3253277554214308, 'bagging_fraction': 0.22054551329713584, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'scale_pos_weight': 1.0154421072327424}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfc6ca-b371-4604-a0e9-0c6f89134edf",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1672880-21ac-420e-b42d-536134720723",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "        'random_state':     42,\n",
    "        'objective':        'binary',\n",
    "        'boosting_type':    'gbdt',\n",
    "        'verbosity':        -1,\n",
    "        'n_estimators':     390,\n",
    "        'lambda_l1':        0.05127158993500609,\n",
    "        'lambda_l2':        0.002856268451232568,\n",
    "        'learning_rate':    0.016316428473444125,\n",
    "        'max_depth':        32,\n",
    "        'num_leaves':       20,\n",
    "        'colsample_bytree': 0.501841654985379, \n",
    "        'colsample_bynode': 0.3253277554214308,\n",
    "        'bagging_fraction': 0.22054551329713584,\n",
    "        'bagging_freq':     5,\n",
    "        'min_data_in_leaf': 9,\n",
    "        'scale_pos_weight': 1.0154421072327424,\n",
    "    }\n",
    "\n",
    "\n",
    "model_lgb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('LGB',  LGBMClassifier(**param_lgb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['lgb']['compute-pauc'] == 1:\n",
    "    pauc_lgb_cv = cross_val_partial_auc_score(X, y, model_lgb_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_lgb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b25bf-63ee-4db4-bc7a-3b724e35592a",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8052b1b2-30d6-482a-9991-0bae08ca26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline                          \n",
    "    model_lgb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('LGB', LGBMClassifier(**param_lgb))\n",
    "    ])\n",
    "    \n",
    "    model_lgb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95539a1-0871-41b9-8beb-1f8f07d1b6c6",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4085524-87a9-4c20-ac12-c2bce12ac75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['save-model'] == 1:\n",
    "    dump(model_lgb_fe139_rsmpl, 'model_lgb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81f006-c34d-4841-8029-f0fee4518b8a",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c1058-b9c6-47de-9a5b-6b170f40d659",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8032cbd-8f95-4e76-98f5-0519b31b0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        loss_function = 'Logloss'\n",
    "        verbose = False\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 400)    \n",
    "        max_depth = trial.suggest_int('max_depth', 1, 16)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0)    \n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1.0, 10.0) #4.0)\n",
    "        l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1.0, 10.0) #8.0)\n",
    "        subsample = trial.suggest_float('subsample', 0.1, 1.0) #0.8)\n",
    "        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 35) # 15, 35)\n",
    "        \n",
    "        pauc_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline\n",
    "            pipe_cb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),  \n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "                ('CAT', CatBoostClassifier(random_state=random_state,                               \n",
    "                                           loss_function=loss_function,\n",
    "                                           verbose=verbose,\n",
    "                                           n_estimators=n_estimators,                               \n",
    "                                           max_depth=max_depth,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           scale_pos_weight=scale_pos_weight,\n",
    "                                           l2_leaf_reg=l2_leaf_reg,\n",
    "                                           subsample=subsample,\n",
    "                                           min_data_in_leaf=min_data_in_leaf,\n",
    "                                        )         \n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_cb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_cb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "# TRIAL\n",
    "#Trial 30 finished with value: 0.19182318666176065\n",
    "#and parameters: {'n_estimators': 352, 'max_depth': 12, 'learning_rate': 0.010916211896675203, 'scale_pos_weight': 1.1308423310589069, 'l2_leaf_reg': 9.938943422516182, 'subsample': 0.48191020552292485, 'min_data_in_leaf': 35}. Best is trial 30 with value: 0.19182318666176065."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb552cde-0c31-428b-be68-9ae476259979",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ee364d3-406c-443e-93ac-22f5ce38fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cb = {\n",
    "        'random_state':     42,\n",
    "        'loss_function':    'Logloss',\n",
    "        'verbose':          False,\n",
    "        'n_estimators':     352,\n",
    "        'max_depth':        12,\n",
    "        'learning_rate':    0.010916211896675203,\n",
    "        'scale_pos_weight': 1.1308423310589069,\n",
    "        'l2_leaf_reg':      9.938943422516182,\n",
    "        'subsample':        0.48191020552292485, \n",
    "        'min_data_in_leaf': 35\n",
    "    }\n",
    "\n",
    "model_cb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('CB',  CatBoostClassifier(**param_cb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['cb']['compute-pauc'] == 1:\n",
    "    pauc_cb_cv = cross_val_partial_auc_score(X, y, model_cb_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_cb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01332b60-72f0-484c-8a5a-f368bf241279",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd287d3-b3cc-418b-8e9c-9dd9f3399ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['final-train'] == 1:\n",
    "        \n",
    "    model_cb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('CAT', CatBoostClassifier(**param_cb)         \n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_cb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afd986-e0c2-4256-9ab6-05edd7290ff1",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0df4f41b-db2f-4b1b-9ada-cedc5725f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['save-model'] == 1:\n",
    "    dump(model_cb_fe139_rsmpl, 'model_cb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3eb52e-12db-412f-9b48-c96206c1fa07",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24a91d-1cd7-44e0-84df-456d0aadad8f",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b47362f1-8505-4e68-98b1-adbfc8673567",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['ada']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0) \n",
    "        \n",
    "        pauc_scores = []\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Pipeline                                       \n",
    "            pipe_ada = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('ADA', AdaBoostClassifier(random_state=42,                             \n",
    "                                           n_estimators=n_estimators,\n",
    "                                           learning_rate=learning_rate                             \n",
    "                                          )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_ada.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_ada.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "\n",
    "#Best trial number: 53\n",
    "#Best value (partial auc - 0.8): 0.19173484739529267\n",
    "#Best hyperparameters: {'n_estimators': 352, 'learning_rate': 0.022798770211700257}\n",
    "\n",
    "#Trial 38 finished with value: 0.19175458060851266 and parameters: {'n_estimators': 276, 'learning_rate': 0.02915033101191371}. Best is trial 38 with value: 0.19175458060851266."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d218132-9ce6-4dce-9400-7b10ae5b0b23",
   "metadata": {},
   "source": [
    "### Cross-validaton Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51159e6-2941-4344-ad66-c8018ffbb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ada = {\n",
    "        'random_state':  42,\n",
    "        'n_estimators':  276, #352,  \n",
    "        'learning_rate': 0.02915033101191371 #0.022798770211700257\n",
    "    }\n",
    "\n",
    "model_ada_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('ADA', AdaBoostClassifier(**param_ada))\n",
    "    ])\n",
    "\n",
    "if ENABLE['ada']['compute-pauc'] == 1:\n",
    "    pauc_ada_cv = cross_val_partial_auc_score(X, y, model_ada_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_ada_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6250aa-9228-4f1b-9450-29070399374a",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30864706-49c5-4f52-a48b-de50008ca947",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['ada']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline                              \n",
    "    model_ada_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('ADA', AdaBoostClassifier(**param_ada)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_ada_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e2a8c-a898-464b-9ff6-31cb8ed5cf95",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04044371-b3a8-46bf-b811-baa71b964753",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['ada']['save-model'] == 1:\n",
    "    dump(model_ada_fe139_rsmpl, 'model_ada_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f00ba-7bb8-4df6-bf36-1ec0c8b854e6",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d55a08ce-78aa-4689-8ae4-840490379e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        probability = True\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        C = trial.suggest_loguniform('C', 0.0001, 10.0)\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        #class_weight = trial.suggest_categorical('class_weight', [None, 'balanced']) \n",
    "        class_weight = 'balanced'\n",
    "        pauc_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline\n",
    "            pipe_svc = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),  \n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "                ('SVC', SVC(random_state=random_state,\n",
    "                            probability=probability,\n",
    "                            kernel=kernel,\n",
    "                            C=C,\n",
    "                            gamma=gamma,\n",
    "                            class_weight=class_weight\n",
    "                           )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_svc.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_svc.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "\n",
    "#Best value (partial auc - 0.8): 0.19117447674037716\n",
    "#Best hyperparameters: {'kernel': 'poly', 'C': 0.0061928828007692584, 'gamma': 'scale', 'class_weight': 'balanced'}.\n",
    "\n",
    "#Trial 27 finished with value: 0.19127118606665136 and parameters: {'kernel': 'linear', 'C': 0.00012545092811368545, 'gamma': 'auto'}. Best is trial 27 with value: 0.19127118606665136."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c03b5-54f8-45f0-a4bb-bf43851a06a8",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "652a1a00-3c4a-46ea-a65c-80da67fc35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svc = {\n",
    "        'random_state': 42,\n",
    "        'probability': True,\n",
    "        'kernel': 'linear',\n",
    "        'C': 0.00012545092811368545,\n",
    "        'gamma': 'auto',\n",
    "        'class_weight': 'balanced'\n",
    "}\n",
    "\n",
    "model_svc_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('SVC', SVC(**param_svc))\n",
    "])\n",
    "\n",
    "if ENABLE['svc']['compute-pauc'] == 1:\n",
    "    pauc_svc_cv = cross_val_partial_auc_score(X, y, model_svc_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_svc_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360753d4-15e8-4539-9dea-f9c8df5f9310",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79b82adb-d96e-49ec-8e23-619df656ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline\n",
    "    model_svc_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('SVC', SVC(**param_svc)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_svc_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd21df1-d7a4-474b-8785-4a24ce9971c2",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c269d5af-7d24-4958-a350-3f6ae2060808",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['save-model'] == 1:\n",
    "    dump(model_svc_fe139_rsmpl, 'model_svc_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93154a3b-1089-421f-9733-12550f0b535d",
   "metadata": {},
   "source": [
    "# Ensemble: Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b60535-d4fe-4acd-af94-d124cb68921b",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3306ef90-19db-4df7-89b3-7d6f70cf2ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1 of 5... pAUC: 0.19137194855164882\n",
      "Processing fold 2 of 5... pAUC: 0.1926880631991458\n",
      "Processing fold 3 of 5... pAUC: 0.18859894050527132\n",
      "Processing fold 4 of 5... pAUC: 0.1934111894368661\n",
      "Processing fold 5 of 5... pAUC: 0.1932032550097425\n",
      "CV Partial AUC Score: 0.1918546793405349\n"
     ]
    }
   ],
   "source": [
    "# Build the soft-voting ensemble archicecture\n",
    "model_soft_cv = VotingClassifier(estimators=[\n",
    "        ('RF',  model_rf_cv),\n",
    "        ('XGB', model_xgb_cv),\n",
    "        ('LGB', model_lgb_cv),\n",
    "        ('CB',  model_cb_cv),\n",
    "        ('ADA', model_ada_cv),\n",
    "        #('SVC', model_svc_cv)\n",
    "], voting='soft')\n",
    "\n",
    "if ENABLE['soft-v']['compute-pauc'] == 1:\n",
    "    pauc_sft_cv = cross_val_partial_auc_score(X, y, model_soft_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_sft_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd62bdd-7e1e-4c00-9ad1-4541b747809b",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a603d4aa-5595-4389-bf0f-5006468fb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['soft-v']['final-train'] == 1:\n",
    "    model_soft_cv_fe130_rsmpl = VotingClassifier(estimators=[\n",
    "        ('RF',  model_rf_cv),\n",
    "        ('XGB', model_xgb_cv),\n",
    "        ('LGB', model_lgb_cv),\n",
    "        ('CB',  model_cb_cv),\n",
    "        ('ADA', model_ada_cv),\n",
    "        ('SVC', model_svc_cv)\n",
    "        ], voting='soft')\n",
    "\n",
    "    # In case that the individual models have been trained before\n",
    "    \n",
    "    #model_rf_fe139_rsmpl = load('model_rf_fe139_rsmpl.pkl')\n",
    "    #model_xgb_fe139_rsmpl = load('model_xgb_fe139_rsmpl.pkl')\n",
    "    #model_lgb_fe139_rsmpl = load('model_lgb_fe139_rsmpl.pkl')\n",
    "    #model_cb_fe139_rsmpl = load('model_cb_fe139_rsmpl.pkl')\n",
    "    #model_cb_fe139_rsmpl = load('model_ada_fe139_rsmpl.pkl')\n",
    "    #model_svc_fe139_rsmpl = load('model_svc_fe139_rsmpl.pkl')\n",
    "    #model_soft_cv_fe130_rsmpl = VotingClassifier(estimators=[\n",
    "    #    ('RF',  model_rf_fe139_rsmpl),\n",
    "    #    ('XGB', model_xgb_fe139_rsmpl),\n",
    "    #    ('LGB', model_lgb_fe139_rsmpl),\n",
    "    #    ('CB',  model_cb_fe139_rsmpl),\n",
    "    #    ('ADA', model_cb_fe139_rsmpl),\n",
    "    #    ('SVC', model_svc_fe139_rsmpl)\n",
    "    #], voting='soft')\n",
    "\n",
    "    model_soft_cv_fe130_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6d8ed-500f-45df-81ac-9c9e709179fa",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed5c0069-0236-4a02-a7fa-b7ea7fa12b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['soft-v']['save-model'] == 1:\n",
    "    dump(model_soft_cv_fe130_rsmpl, 'model_soft_cv_fe130_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b11ce7-1ea5-418f-a339-12a17a41720a",
   "metadata": {},
   "source": [
    "# Ensemble: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "779571e7-35bf-40bb-b082-a3db9d305343",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 1 (2417230151.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[88], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    estimators=[\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 1\n"
     ]
    }
   ],
   "source": [
    "if ENABLE['lr-v']['cross-val'] == 1:\n",
    "    \n",
    "estimators=[\n",
    "        ('RF',  model_rf_cv),\n",
    "        ('XGB', model_xgb_cv),\n",
    "        ('LGB', model_lgb_cv),\n",
    "        ('CB',  model_cb_cv),\n",
    "        ('ADA', model_ada_cv),\n",
    "        ('SVC', model_svc_cv)\n",
    "\n",
    "stacking_lr = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Construct a pipeline with StackingClassifier\n",
    "pipe_lr_soft = Pipeline([\n",
    "    ('stacking_clf', stacking_lr)\n",
    "])\n",
    "\n",
    "\n",
    "# Define hyperparameters only for LogisticRegression()\n",
    "hyperparams = {\n",
    "    'stacking_clf__final_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'stacking_clf__final_estimator__penalty': ['l1', 'l2'],\n",
    "    'stacking_clf__final_estimator__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "#meta = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3c97260-4dc2-459f-9f1b-3866263c7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-28 11:08:59,632] A new study created in memory with name: no-name-127e983a-a0be-4b1c-abf0-0f194cf16ce2\n",
      "[I 2024-08-28 11:39:29,162] Trial 0 finished with value: 0.18996824374324256 and parameters: {'C': 0.4454395767141481, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 0 with value: 0.18996824374324256.\n",
      "[I 2024-08-28 12:11:51,379] Trial 1 finished with value: 0.18976532074970778 and parameters: {'C': 3.3930740912105417, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 0 with value: 0.18996824374324256.\n",
      "[I 2024-08-28 12:33:37,795] Trial 2 finished with value: 0.19212974289656715 and parameters: {'C': 0.37206196533421637, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 2 with value: 0.19212974289656715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial number: 2\n",
      "Best value (partial auc - 0.8): 0.19212974289656715\n",
      "Best hyperparameters: {'C': 0.37206196533421637, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "if ENABLE['lr-v']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function for Optuna\n",
    "    def objective(trial):\n",
    "        \n",
    "        # Suggest values for the hyperparameters of Logistic Regression\n",
    "        C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "        solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "        \n",
    "        pauc_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # Pipeline with preprocessing and logistic regression\n",
    "            pipe_lr = Pipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('logreg', LogisticRegression(\n",
    "                    C=C,\n",
    "                    penalty=penalty,\n",
    "                    solver=solver,\n",
    "                    max_iter=1000,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ])\n",
    "            \n",
    "            # Train the model\n",
    "            pipe_lr.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_lr.predict_proba(X_val_fold)[:, 1]\n",
    "        \n",
    "            # Calculate partial AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=3, n_jobs=1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa7e0b0c-8af7-4093-85a0-76b04797d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 7 finished with value: 0.19230752612288346 and parameters: {'C': 1.4669795429403636, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 7 with value: 0.19230752612288346.\n",
    "# Trial 4 finished with value: 0.19185952072646328 and parameters: {'C': 9.5120708822337, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 4 with value: 0.19185952072646328\n",
    "# Trial 3 finished with value: 0.19208920555615153 and parameters: {'C': 0.25814369656714853, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 3 with value: 0.19208920555615153."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c80153-1f1a-4f3a-a916-a53f85012055",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254cf19-026d-4134-85cd-e0c48cd354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lr-v']['compute-pauc'] == 1:\n",
    "    # Separate numerical and categorical columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Preprocessing for numerical data: Standard Scaler\n",
    "    numerical_transformer = StandardScaler()\n",
    "\n",
    "    # Preprocessing for categorical data: OneHot Encoder\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Combine preprocessing steps using ColumnTransformer\n",
    "    preprocessing = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the best parameters directly from Trial 7\n",
    "    param_lr_v = {\n",
    "        'C': 1.4669795429403636,  \n",
    "        'penalty': 'l1',         \n",
    "        'solver': 'liblinear'     \n",
    "    }\n",
    "\n",
    "    # Build the Logistic Regression model with the best parameters in a pipeline\n",
    "    model_lr_cv = Pipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('logreg', LogisticRegression(**param_lr_v, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Function for cross-validation to calculate the partial AUC score\n",
    "    def cross_val_partial_auc_score(X, y, model, n_splits=5):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        pauc_scores = []\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict on the validation set\n",
    "            preds = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "            # Calculate partial AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "\n",
    "        return np.mean(pauc_scores)\n",
    "\n",
    "    # Perform cross-validation to calculate the partial AUC score\n",
    "    pauc_lr_cv = cross_val_partial_auc_score(X, y, model_lr_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score for Logistic Regression: {pauc_lr_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7a95d-6098-4e68-b416-a7f6c16fa998",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a3496-8c7c-4fe0-b780-b754d469166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lr-v']['final-train'] == 1:\n",
    "\n",
    "    # Use the best parameters found from Optuna for Logistic Regression\n",
    "    param_lr_v = {\n",
    "        'C': 1.4669795429403636,  # Value from best trial\n",
    "        'penalty': 'l1',          # Value from best trial\n",
    "        'solver': 'liblinear'     # Value from best trial\n",
    "    }\n",
    "\n",
    "    # Define the base estimators for stacking\n",
    "    estimators = [\n",
    "        ('RF',  model_rf_cv),   # Random Forest Classifier model\n",
    "        ('XGB', model_xgb_cv),  # XGBoost Classifier model\n",
    "        ('LGB', model_lgb_cv),  # LightGBM Classifier model\n",
    "        ('CB',  model_cb_cv),   # CatBoost Classifier model\n",
    "        ('ADA', model_ada_cv),  # AdaBoost Classifier model\n",
    "        ('SVC', model_svc_cv)   # Support Vector Classifier model\n",
    "    ]\n",
    "\n",
    "    # Define the stacking classifier with Logistic Regression as the final estimator\n",
    "    stacking_lr = StackingClassifier(\n",
    "        estimators=estimators, \n",
    "        final_estimator=LogisticRegression(**param_lr_v, max_iter=1000, random_state=42)\n",
    "    )\n",
    "\n",
    "    # Construct a pipeline with StackingClassifier\n",
    "    model_lr_cv_fe130_rsmpl = Pipeline([('stacking_clf', stacking_lr)])\n",
    "\n",
    "    # Fit the pipeline on the entire dataset\n",
    "    model_lr_cv_fe130_rsmpl.fit(X, y)\n",
    "\n",
    "    print(\"Stacking Classifier trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59703cd3-03b1-4df6-9572-6b5eb517c8b8",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff0c2fed-acad-47b1-99b4-4769cc8cd925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Scores:\n",
      "\n",
      "Model           Partial AUC Score   \n",
      "-----------------------------------\n",
      "Soft Voting     0.1920              \n"
     ]
    }
   ],
   "source": [
    "print(\"Model Performance Scores:\\n\")\n",
    "print(f\"{'Model':<15} {'Partial AUC Score':<20}\")\n",
    "print(\"-\" * 35)\n",
    "if 'pauc_rf_cv' in locals():\n",
    "    print(f\"{'Random Forest':<15} {pauc_rf_cv:<20.4f}\")\n",
    "if 'pauc_xgb_cv' in locals():    \n",
    "    print(f\"{'XGBoost':<15} {pauc_xgb_cv:<20.4f}\")\n",
    "if 'pauc_lgb_cv' in locals():    \n",
    "    print(f\"{'LightGBM':<15} {pauc_lgb_cv:<20.4f}\")\n",
    "if 'pauc_cb_cv' in locals():        \n",
    "    print(f\"{'CatBoost':<15} {pauc_cb_cv:<20.4f}\")\n",
    "if 'pauc_ada_cv' in locals():    \n",
    "    print(f\"{'AdaBoost':<15} {pauc_ada_cv:<20.4f}\")\n",
    "if 'pauc_svc_cv' in locals():        \n",
    "    print(f\"{'SVC':<15} {pauc_svc_cv:<20.4f}\")\n",
    "if 'pauc_sft_cv' in locals():        \n",
    "    print(f\"{'Soft Voting':<15} {pauc_sft_cv:<20.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c764d40a-5680-4e9c-bb2f-e73be35e30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross-validation\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#pauc_scores = []\n",
    "\n",
    "# Cross-validation loop\n",
    "#for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "    # Create the folds\n",
    "#    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Create the ensemble model. Assumed these models already pretrained\n",
    "#    soft_voting_model = VotingClassifier(estimators=[\n",
    "#        ('RF',  model_rf_fe139_rsmpl),\n",
    "#        ('XGB', model_xgb_fe139_rsmpl),\n",
    "#        ('LGB', model_lgb_fe139_rsmpl),\n",
    "#        ('CB',  model_cb_fe139_rsmpl),\n",
    "#        ('ADA', model_ada_fe139_rsmpl),\n",
    "#        ('SVC', model_svc_fe139_rsmpl),\n",
    "        \n",
    "    # Make predictions with the validation set\n",
    "    #preds1 = model_rf_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds2 = model_xgb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds3 = model_lgb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds4 = model_cb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds5 = model_ada_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds6 = model_svc_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "\n",
    "    #pauc1 = partial_auc_score(y_val_fold, preds1)\n",
    "    #pauc2 = partial_auc_score(y_val_fold, preds2)\n",
    "    #pauc3 = partial_auc_score(y_val_fold, preds3)\n",
    "    #pauc4 = partial_auc_score(y_val_fold, preds4)\n",
    "    #pauc5 = partial_auc_score(y_val_fold, preds5)\n",
    "    #pauc6 = partial_auc_score(y_val_fold, preds6)\n",
    "    \n",
    "    # Combine the partial AUC scores using the average\n",
    "    #pauc_ave = np.mean([preds1, preds2, preds3, preds4, preds5, preds6])\n",
    "\n",
    "    # Predict on the validation set\n",
    "#    preds = soft_voting_model.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "    # Calculate partical AUC and store it\n",
    "#    pauc = partial_auc_score(y_val_fold, preds)\n",
    "#    pauc_scores.append(pauc)\n",
    "\n",
    "# Average the scores across all folds\n",
    "#average_ensemble_score = np.mean(pauc_scores)\n",
    "#print(f'Average partical AUC score - Soft Voting: {average_ensemble_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48e7f838-7fe0-4605-a795-ec44ba834780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ba93eb3-6a65-4c04-8b56-1c3c72fd7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importances = model.feature_importances_\n",
    "#feature_importance_df = pd.DataFrame({\n",
    "#    'feature': selected_features,  # This should correspond to your final set of features after KBest\n",
    "#    'importance': importances\n",
    "#}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "#sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "#plt.title('Feature Importance')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c1fc0-365a-435d-8b47-cc4fafa872ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0cddc-ddbc-425f-a637-821ab6fd8b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
