{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f52785-438b-40f7-9ac8-2fcd3df4a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "#from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "import tensorflow as tf\n",
    "\n",
    "# From TensorFlow\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, RandomRotation\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, ResNet50V2, EfficientNetB0, EfficientNetB5, EfficientNetB7, DenseNet121, ResNet152V2, Xception, InceptionV3, NASNetMobile, DenseNet201, InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.models import load_model, Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import AUC, PrecisionAtRecall, SpecificityAtSensitivity, PrecisionAtRecall\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# From scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#set_global_policy('mixed_float16')\n",
    "set_global_policy('float32')\n",
    "\n",
    "SEED = 2024\n",
    "\n",
    "# Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Force deterministic behavior\n",
    "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "#os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "#os.environ['OMP_NUM_THREADS'] = '1'\n",
    "#os.environ['TF_NUM_INTRAOP_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61af96-0a18-4379-9110-55a6a8b6bcab",
   "metadata": {},
   "source": [
    "# GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce28b6-e439-4fff-8170-0412590d970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detected: {gpus}\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f4fa7-f20e-490d-9079-e6019e10d242",
   "metadata": {},
   "source": [
    "# Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5b76a-44a5-43e7-96cc-c117f523fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "IM_SIZE = 128\n",
    "EPOCHS = 60\n",
    "LEARN_RATE = 0.0001\n",
    "REG_RATE = 0.001\n",
    "NEURONS_1 = 1024\n",
    "NEURONS_2 = 1024\n",
    "NEURONS_3 = 256\n",
    "DROPOUT_RATE = 0.5\n",
    "TRAIN_TEST_SPLIT = 0.15\n",
    "ACTIVATION = 'relu'\n",
    "VERSION = '1'\n",
    "\n",
    "# Read the dataset\n",
    "ROOT_DATASET_DIR = \"../\"\n",
    "DATASET = os.path.join(ROOT_DATASET_DIR,\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc3a45-2d86-43cf-a7f9-823ad7d9a98c",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3863a7-37f8-4e8d-a471-0a7060fa449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting model loss during training, created by Daniel: https://medium.com/geekculture/how-to-plot-model-loss-while-training-in-tensorflow-9fa1a1875a5\n",
    "class plot_learning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b40f8-9bfb-49ee-a261-4ff60f7d566a",
   "metadata": {},
   "source": [
    "# Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dff23-ed2f-4c6e-b88d-21529c3a9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for custom normalization\n",
    "def custom_normalization(image):\n",
    "    image = image / 255.0\n",
    "    mean = tf.constant(MEAN, dtype=image.dtype)\n",
    "    std = tf.constant(STD, dtype=image.dtype)\n",
    "    image = (image - mean) / std  # Normalize each channel\n",
    "    return image\n",
    "\n",
    "rotate_image = RandomRotation(factor=0.2)\n",
    "\n",
    "def random_zoom(image, min_val=0.8, max_val=1.2):\n",
    "    # Random zoom\n",
    "    zoom_scale = tf.random.uniform([], minval=min_val, maxval=max_val)\n",
    "    original_size = tf.shape(image)[0:2]\n",
    "    new_size = tf.cast(zoom_scale * tf.cast(original_size, tf.float32), tf.int32)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, new_size[0], new_size[1])\n",
    "    image = tf.image.resize(image, original_size)\n",
    "    return image\n",
    "    \n",
    "# Function to add Gaussian noise\n",
    "def gaussian_noise(image, mean=0.0, stddev=0.1):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "    image = tf.add(image, noise)\n",
    "    return image\n",
    "\n",
    "def gaussian_blur(image, kernel_size=5, sigma=1.0): \n",
    "    kernel = gaussian_kernel(kernel_size, 0.0, sigma)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.squeeze(image, axis=0)\n",
    "    \n",
    "# Image augmentation\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)  # Horizontal flip\n",
    "    image = tf.image.random_flip_up_down(image) # Vertical flip\n",
    "    #angle = tf.random.uniform([], minval=-20, maxval=20)\n",
    "    image = rotate_image(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)  # Random brightness\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)  # Random contrast\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)  # Random saturation\n",
    "    #image = random_zoom(image, min_val=0.8, max_val=1.2)\n",
    "    #image = tf.image.random_hue(image, max_delta=0.1)\n",
    "    #image = gaussian_noise(image, mean=0.0, stddev=0.1) \n",
    "    #image = gaussian_blur(image, kernel_size=5, sigma=1.0)\n",
    "    return image, label\n",
    "\n",
    "# Parse and process images\n",
    "def parse_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IM_SIZE, IM_SIZE]) #, method=tf.image.ResizeMethod.LANCZOS3)\n",
    "    image = custom_normalization(image)\n",
    "    return image, label\n",
    "\n",
    "# Generate dataset from file paths\n",
    "def generate_dataset(file_paths, labels, batch_size, is_training):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=1000)  # Use a reasonable buffer size\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# List image paths and labels\n",
    "def get_image_paths_and_labels(directory):\n",
    "    data_dir = Path(directory)    \n",
    "    all_image_paths = list(data_dir.glob('*/*.jpg'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]    \n",
    "    all_labels = [0 if '\\\\0' in str(path) else 1 for path in all_image_paths]\n",
    "    return all_image_paths, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c7a50-8bb8-424b-9496-9ebed62d4b99",
   "metadata": {},
   "source": [
    "# Resampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d11eee-bc1f-4ccb-bd0b-d41e5ef0b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to undersample the majority class and oversample the minority class\n",
    "def balance_classes(image_paths, labels, majority_size=None, minority_size=None, seed=SEED):\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = image_paths[labels == 0]\n",
    "    majority_labels = labels[labels == 0]\n",
    "    \n",
    "    minority_class = image_paths[labels == 1]\n",
    "    minority_labels = labels[labels == 1]\n",
    "    \n",
    "    # Undersample the majority class if majority_size is specified\n",
    "    if majority_size and (majority_size < len(majority_class)):\n",
    "        majority_class_downsampled, majority_labels_downsampled = resample(\n",
    "            majority_class,\n",
    "            majority_labels,\n",
    "            replace=False,  # Sample without replacement\n",
    "            n_samples=majority_size,  # Number of samples after undersampling\n",
    "            random_state=seed  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        majority_class_downsampled, majority_labels_downsampled = majority_class, majority_labels\n",
    "    \n",
    "    # Oversample the minority class if minority_size is specified\n",
    "    if minority_size and (minority_size > len(minority_class)):\n",
    "        minority_class_upsampled, minority_labels_upsampled = resample(\n",
    "            minority_class,\n",
    "            minority_labels,\n",
    "            replace=True,  # Sample with replacement\n",
    "            n_samples=minority_size,  # Number of samples after oversampling\n",
    "            random_state=seed  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        minority_class_upsampled, minority_labels_upsampled = minority_class, minority_labels\n",
    "    \n",
    "    # Combine the undersampled majority class and upsampled minority class\n",
    "    balanced_image_paths = np.concatenate([majority_class_downsampled, minority_class_upsampled])\n",
    "    balanced_labels = np.concatenate([majority_labels_downsampled, minority_labels_upsampled])\n",
    "    \n",
    "    return balanced_image_paths.tolist(), balanced_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67f60d-8a4b-4177-87ba-7fa93d886095",
   "metadata": {},
   "source": [
    "# Create the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b3836-57fa-4a4d-b588-c3596c9b02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the convolutional neural network. Based on ResNet152V2, the whole backbone and hidden layer will be trainen to achieve more accurate predictions\n",
    "def create_cnn_model(base_model):\n",
    "\n",
    "    # Enable backbone training\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Generate a neural network with one hidden layer of 64 neurons\n",
    "    x = GlobalAveragePooling2D()(base_model.output)    \n",
    "    x = Dense(NEURONS_1, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    x = Dense(NEURONS_2, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    x = Dense(NEURONS_3, kernel_initializer=glorot_uniform(seed=SEED), activation=ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE, seed=SEED)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Define optimizer and evaluation metrics\n",
    "    optimizer = Adam(learning_rate=LEARN_RATE)\n",
    "    eval_metrics = [\"accuracy\", AUC(from_logits=False), SpecificityAtSensitivity(sensitivity=0.8)]\n",
    "\n",
    "    # And compile\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=eval_metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927ef77-41ab-440e-88f3-98e72802fb43",
   "metadata": {},
   "source": [
    "# Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8306b0-d320-44a1-a10f-f7265bb89e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    all_image_paths, all_labels = get_image_paths_and_labels(DATASET + '/crossval')\n",
    "\n",
    "    # Frequency of class 1 (malignant cases)\n",
    "    n_class_1 = all_labels.count(1)\n",
    "\n",
    "    cnn_model_list = {\n",
    "        # Backbone           seed \n",
    "        'DenseNet121':       1337,\n",
    "        'DenseNet201':       2001,\n",
    "        'EfficientNetB0':    2023,\n",
    "        'InceptionResNetV2':   23,\n",
    "        'InceptionV3':        313,\n",
    "        'NASNetMobile':      1024,                              \n",
    "        'ResNet152V2':          7,\n",
    "        'Xception':           100\n",
    "    }\n",
    "\n",
    "    # Loop over models\n",
    "    for MODEL, SEED_BALANCED in cnn_model_list.items():\n",
    "\n",
    "        if MODEL == 'DenseNet121':\n",
    "            base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'DenseNet201':\n",
    "            base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'EfficientNetB0':\n",
    "            base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'InceptionResNetV2':\n",
    "            base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'InceptionV3':\n",
    "            base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'NASNetMobile':\n",
    "            base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'ResNet152V2':\n",
    "            base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'ResNet50V2':\n",
    "            base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "        elif MODEL == 'Xception':\n",
    "            base_model = Xception(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "\n",
    "        # Balance the classes by undersampling and oversampling\n",
    "        train_paths_balanced, train_labels_balanced = balance_classes(\n",
    "            all_image_paths, \n",
    "            all_labels, \n",
    "            majority_size=n_class_1 * 10,\n",
    "            minority_size=n_class_1 * 10,\n",
    "            seed=SEED_BALANCED\n",
    "        )\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        train_paths, validation_paths, train_labels, validation_labels = train_test_split(\n",
    "            train_paths_balanced, train_labels_balanced, \n",
    "            test_size=TRAIN_TEST_SPLIT,\n",
    "            stratify=train_labels_balanced,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = generate_dataset(train_paths, train_labels, BATCH_SIZE, is_training=True)\n",
    "        validation_dataset = generate_dataset(validation_paths, validation_labels, BATCH_SIZE, is_training=False)\n",
    "\n",
    "        # Train the model\n",
    "        lowest = 1000\n",
    "        EPOCHS_ = EPOCHS + 10 if MODEL == 'NASNetMobile' else EPOCHS\n",
    "        for trials in range(5):\n",
    "            \n",
    "            # Create and compile the CNN model\n",
    "            cnn_model_trial = create_cnn_model(base_model)\n",
    "        \n",
    "            # Checkpoint callbacks\n",
    "            best_checkpoint_path = f\"{MODEL}_nn{NEURONS_1}-{NEURONS_2}-{NEURONS_3}_lr{int(LEARN_RATE * 10000):04}_{ACTIVATION}_batch{BATCH_SIZE}_epoch{EPOCHS}_{VERSION}_best.keras\"\n",
    "            best_checkpoint_callback = ModelCheckpoint(filepath=best_checkpoint_path, monitor=\"val_loss\", save_best_only=True)\n",
    "        \n",
    "            final_checkpoint_path = f\"{MODEL}_nn{NEURONS_1}-{NEURONS_2}-{NEURONS_3}_lr{int(LEARN_RATE * 10000):04}_{ACTIVATION}_batch{BATCH_SIZE}_epoch{EPOCHS}_{VERSION}_final.keras\"\n",
    "            final_checkpoint_callback = ModelCheckpoint(filepath=final_checkpoint_path)\n",
    "        \n",
    "            # Reducing learning rate\n",
    "            reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, min_lr=1e-7)\n",
    "\n",
    "            # Specify callbacks\n",
    "            callbacks = [plot_learning(), best_checkpoint_callback, final_checkpoint_callback, reduce_lr_callback] if MODEL != 'EfficientNetB0' else [plot_learning(), reduce_lr_callback]\n",
    "\n",
    "            # Train\n",
    "            history = cnn_model_trial.fit(\n",
    "                train_dataset,\n",
    "                batch_size=BATCH_SIZE,    \n",
    "                epochs=EPOCHS_,\n",
    "                verbose=1,\n",
    "                validation_data=validation_dataset,    \n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            cnn_model_trial = load_model(best_checkpoint_path) if MODEL != 'EfficientNetB0' else cnn_model_trial\n",
    "            loss = cnn_model_trial.evaluate(validation_dataset)\n",
    "            if loss[0] < lowest:\n",
    "                cnn_model = cnn_model_trial\n",
    "                lowest = loss[0] \n",
    "\n",
    "        # Evaluate the best model on the validation set\n",
    "        _ = cnn_model.evaluate(validation_dataset)\n",
    "\n",
    "        # Save model weights\n",
    "        cnn_model.save_weights(f\"{MODEL}_nn{NEURONS_1}-{NEURONS_2}-{NEURONS_3}_lr{int(LEARN_RATE * 10000):04}_{ACTIVATION}_batch{BATCH_SIZE}_epoch{EPOCHS}_kaggle_weights_{VERSION}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf_gpu (py310)",
   "language": "python",
   "name": ".venv_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
